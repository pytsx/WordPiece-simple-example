# WordPiece
 This project uses WordPiece tokenizer to encode input text into a sequence of tokens. The tokenizer is trained using a training dataset with a WordPieceTrainer, which can generate a vocabulary of subwords. It can then tokenize any input text.
